apiVersion: v1
kind: ConfigMap
metadata:
  name: inference-config
  namespace: default
data:
  INITIAL_MODEL_REPO_ID: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
  HF_HOME: "/models/hf_home"
  TRANSFORMERS_CACHE: "/models/transformers_cache"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: trainer-config
  namespace: default
data:
  INITIAL_MODEL: "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
  SUBSTITUTE_MODEL: "Qwen/Qwen2.5-7B-Instruct"
  # Use headless service to access individual pods
  # Format: http://inference-headless.default.svc.cluster.local:8000
  # In practice, you may need to discover pod IPs or use StatefulSet for predictable names
  # For now, using the regular service - trainer will update via file-based sync
  INFERENCE_URLS: "http://inference-headless.default.svc.cluster.local:8000"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ui-config
  namespace: default
data:
  # UI needs individual pod URLs for status checks
  # Using headless service - in practice, you may need to discover pod endpoints
  # Alternative: Use regular service and rely on load balancing
  INFERENCE_URLS: "http://inference-service:8000"
  TRAINER_URL: "http://trainer-service:8080"